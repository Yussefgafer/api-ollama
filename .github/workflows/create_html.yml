# .github/workflows/run-ollama-llm.yml
name: Run Ollama LLM on GitHub Actions

on:
  workflow_dispatch: # يسمح بتشغيل السير عمل يدوياً
    inputs:
      prompt:
        description: 'النص الذي تريد أن يعالجه النموذج'
        required: true
        default: 'Why is the sky blue?'
      model_name:
        description: 'اسم النموذج الذي تريد سحبه وتشغيله (مثال: llama2, mistral)'
        required: true
        default: 'llama2'

jobs:
  run-llm:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Install Ollama
        run: |
          # تنزيل وتثبيت Ollama
          curl -fsSL https://ollama.com/install.sh | sh
          # التأكد من أن Ollama يعمل
          ollama --version
          echo "Ollama installed successfully."

      - name: Start Ollama in background
        run: |
          # تشغيل Ollama كعملية في الخلفية
          ollama serve &
          # الانتظار قليلاً للتأكد من بدء تشغيل Ollama
          sleep 5
          echo "Ollama server started."

      - name: Pull LLM Model
        run: |
          echo "Pulling model: ${{ github.event.inputs.model_name }}"
          ollama pull ${{ github.event.inputs.model_name }}
          echo "Model pulled successfully."

      - name: Run LLM with Prompt
        id: llm_output # لتخزين مخرجات هذه الخطوة
        run: |
          echo "Running model with prompt: ${{ github.event.inputs.prompt }}"
          # استخدام curl للتفاعل مع Ollama API
          # يمكنك استخدام أي لغة برمجة هنا (Python, Node.js) بدلاً من curl
          response=$(curl -s http://localhost:11434/api/generate -d '{
            "model": "${{ github.event.inputs.model_name }}",
            "prompt": "${{ github.event.inputs.prompt }}",
            "stream": false
          }')
          
          # استخراج النص الناتج من الاستجابة
          generated_text=$(echo "$response" | jq -r '.response')
          echo "Generated Text:"
          echo "$generated_text"
          
          # إخراج النص الناتج كمتغير للسير عمل
          echo "generated_text=$generated_text" >> "$GITHUB_OUTPUT"
        env:
          # التأكد من تثبيت jq في بيئة GitHub Actions
          DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y jq

      - name: Display LLM Output
        run: |
          echo "The LLM generated the following response:"
          echo "${{ steps.llm_output.outputs.generated_text }}"